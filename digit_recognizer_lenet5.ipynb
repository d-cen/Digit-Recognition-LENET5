{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognizer_lenet5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Recognizer with LeNet 5"
      ],
      "metadata": {
        "id": "HJtPRH2EoYGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "OZtKXy5Zprea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import libraries"
      ],
      "metadata": {
        "id": "rbKbDycDOrNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YeVrf_8uOp-d"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Loading dataset from directory"
      ],
      "metadata": {
        "id": "W7PwRo8y1bT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive to Colab to serve as local directory\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo-PmqXwpvDN",
        "outputId": "0fd72543-f150-46ed-ec42-9cb32784ac82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "dir_root = \"/content/drive/MyDrive/Kaggle/Digit_Recognizer/Data/digit-recognizer\"\n",
        "train_dir = os.path.join(dir_root, \"train.csv\")\n",
        "train = pd.read_csv(train_dir, dtype=np.float32)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "_WDHLD-vqKwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "48aea3ff-a6c4-4eec-fdf6-92aed09a33ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "1    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "2    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "3    4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "4    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "1     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "2     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "3     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "4     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "   pixel780  pixel781  pixel782  pixel783  \n",
              "0       0.0       0.0       0.0       0.0  \n",
              "1       0.0       0.0       0.0       0.0  \n",
              "2       0.0       0.0       0.0       0.0  \n",
              "3       0.0       0.0       0.0       0.0  \n",
              "4       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1555c50-902d-4a36-b124-c8cef177add8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1555c50-902d-4a36-b124-c8cef177add8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1555c50-902d-4a36-b124-c8cef177add8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1555c50-902d-4a36-b124-c8cef177add8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and labels\n",
        "X_train = train.loc[:, train.columns != \"label\"]\n",
        "Y_train = train.label"
      ],
      "metadata": {
        "id": "tWd035ZyPXvZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Check for data inbalance or missing value"
      ],
      "metadata": {
        "id": "eNrNeKq5PrIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if contain null features\n",
        "X_train.isnull().any().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OouWHuxCP5Cy",
        "outputId": "130fd031-3905-4150-eb22-1bb51312306f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       784\n",
              "unique        1\n",
              "top       False\n",
              "freq        784\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for counts\n",
        "label_count = Y_train.value_counts()\n",
        "print(label_count)\n",
        "g = sns.countplot(x=Y_train)\n",
        "g = g.set(xlabel=\"Label\", ylabel=\"Count\", title=\"Label Count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "LnSmSjN1SgFL",
        "outputId": "54b30fcb-442c-4b5d-9c1d-ec3bf7a97fc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    4684\n",
            "7.0    4401\n",
            "3.0    4351\n",
            "9.0    4188\n",
            "2.0    4177\n",
            "6.0    4137\n",
            "0.0    4132\n",
            "4.0    4072\n",
            "8.0    4063\n",
            "5.0    3795\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Normalization and transformation"
      ],
      "metadata": {
        "id": "nqnS993XLMCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Perform grayscale normalization to \n",
        "1. Reduce illumination differences\n",
        "2. Increase CNN covergence rate\n",
        "'''\n",
        "X_train = X_train / 255.0"
      ],
      "metadata": {
        "id": "T-6a45tkQvqY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training and test set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_train.values, \n",
        "    Y_train.values, \n",
        "    test_size=0.1, \n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# Reshape input image\n",
        "X_train = X_train.reshape((-1, 1, 28, 28))\n",
        "X_train = np.squeeze(X_train, axis=1)\n",
        "X_test = X_test.reshape((-1, 1, 28, 28))\n",
        "X_test = np.squeeze(X_test, axis=1)\n",
        "\n",
        "# Transform from numpy arrays to tensors\n",
        "Y_train = torch.from_numpy(Y_train).type(torch.FloatTensor)\n",
        "Y_test = torch.from_numpy(Y_test).type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "gw_Tj5EbRW_k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "g = plt.imshow(X_train[0][:,:], cmap=\"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XPRvYuhlXvr3",
        "outputId": "b32e805a-3deb-4f13-c7f0-f6e1f5619af7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MNIST data class\n",
        "transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "class MNIST(Dataset):\n",
        "    def __init__(self, X, Y, Transform):\n",
        "        self.X = X\n",
        "        self.transform = Transform\n",
        "        self.Y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transform(self.X[index]), self.Y[index]\n",
        "\n",
        "batch_size_train, batch_size_test = 64, 1000\n",
        "train_set = MNIST(X_train, Y_train, transform_train)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_set = MNIST(X_test, Y_test, transform_train)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size_test, shuffle=False)"
      ],
      "metadata": {
        "id": "P8drJS9eZi_S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "NS12pIuU0gIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create CNN Model"
      ],
      "metadata": {
        "id": "lH2lgR7V0kU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2EkUe-a61muz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783b3b4d-d4ef-463a-dfa2-7b5a36470ab0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_feature = 10\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    '''\n",
        "    This implementation follow LeNet5's design from \"Gradient-based learning\n",
        "    applied to document recognition\" by Y.Lecun with several modifications.\n",
        "    \n",
        "    - Two 3x3 filters replaced single 5x5 filter in conv2d layer 3\n",
        "    - Batch normalization added\n",
        "    - ReLU activation function replaced tanh\n",
        "    - More channels added\n",
        "    - Dropout added\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(p=0.25),\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.Dropout2d(p=0.25),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=3136, out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.BatchNorm1d(num_features=256),\n",
        "            nn.Linear(in_features=256, out_features=latent_feature)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Y-qTEHgRz4g9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Instantiate model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "FBZTpbZLftA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model and move to GPU if available\n",
        "model = LeNet5()\n",
        "LeNet5_classifier = model.to(device)\n",
        "\n",
        "# Instantiate loss function\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "# Instantiate optimizer\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(LeNet5_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate number of epoch, losses, score\n",
        "max_epoch = 30\n",
        "train_losses, test_losses = [], []\n",
        "best_score = 0\n",
        "best_model = None"
      ],
      "metadata": {
        "id": "PTqoB-1RfEEj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train and test the model"
      ],
      "metadata": {
        "id": "7AKTJ0Xnf87X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(classifier, epoch):\n",
        "\n",
        "    classifier.train()\n",
        "\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = classifier(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 10 == 0: # Record output every 10 batches\n",
        "            train_losses.append(loss.item())\n",
        "        if idx % 100 == 0: # Visualize output every 100 batches\n",
        "            print(f\"Epoch {epoch}: [{idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "tz9KwFb6ljRI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(classifier, epoch, best_score):\n",
        "    \n",
        "    classifier.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(test_loader):\n",
        "            \n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = classifier(images)\n",
        "            test_loss += loss_fn(output, labels).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1] # Get estimate of result by looking at largest class value\n",
        "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    acc_val = correct/len(test_loader.dataset)\n",
        "    print(f\"Test result on epoch {epoch}: Avg loss is {test_loss:.6f}, Accuracy: {100.*acc_val:.6f}%\", end=\" \")\n",
        "    if best_score <= acc_val.item():\n",
        "        best_score = copy.deepcopy(acc_val.item())\n",
        "        best_model = copy.deepcopy(classifier)\n",
        "        print(\"(New Best Score)\")\n",
        "    else:\n",
        "        print()\n",
        "    return best_score"
      ],
      "metadata": {
        "id": "hnEbQWnFgjGj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, max_epoch+1):\n",
        "    train(LeNet5_classifier, epoch)\n",
        "    best_score = test(LeNet5_classifier, epoch, best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQsPY4bNfO48",
        "outputId": "49964571-97cd-475c-95db-53eef1fab11e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: [0/37800] Loss: 0.024905\n",
            "Epoch 1: [6400/37800] Loss: 0.010799\n",
            "Epoch 1: [12800/37800] Loss: 0.040260\n",
            "Epoch 1: [19200/37800] Loss: 0.020823\n",
            "Epoch 1: [25600/37800] Loss: 0.011986\n",
            "Epoch 1: [32000/37800] Loss: 0.005517\n",
            "Test result on epoch 1: Avg loss is 0.000033, Accuracy: 99.166664% (New Best Score)\n",
            "Epoch 2: [0/37800] Loss: 0.019940\n",
            "Epoch 2: [6400/37800] Loss: 0.042520\n",
            "Epoch 2: [12800/37800] Loss: 0.106030\n",
            "Epoch 2: [19200/37800] Loss: 0.077426\n",
            "Epoch 2: [25600/37800] Loss: 0.018457\n",
            "Epoch 2: [32000/37800] Loss: 0.009451\n",
            "Test result on epoch 2: Avg loss is 0.000034, Accuracy: 99.166664% (New Best Score)\n",
            "Epoch 3: [0/37800] Loss: 0.011831\n",
            "Epoch 3: [6400/37800] Loss: 0.057239\n",
            "Epoch 3: [12800/37800] Loss: 0.226552\n",
            "Epoch 3: [19200/37800] Loss: 0.168799\n",
            "Epoch 3: [25600/37800] Loss: 0.011063\n",
            "Epoch 3: [32000/37800] Loss: 0.015229\n",
            "Test result on epoch 3: Avg loss is 0.000044, Accuracy: 99.142853% \n",
            "Epoch 4: [0/37800] Loss: 0.004673\n",
            "Epoch 4: [6400/37800] Loss: 0.021547\n",
            "Epoch 4: [12800/37800] Loss: 0.018493\n",
            "Epoch 4: [19200/37800] Loss: 0.009579\n",
            "Epoch 4: [25600/37800] Loss: 0.003123\n",
            "Epoch 4: [32000/37800] Loss: 0.016147\n",
            "Test result on epoch 4: Avg loss is 0.000032, Accuracy: 99.261902% (New Best Score)\n",
            "Epoch 5: [0/37800] Loss: 0.009764\n",
            "Epoch 5: [6400/37800] Loss: 0.005241\n",
            "Epoch 5: [12800/37800] Loss: 0.078029\n",
            "Epoch 5: [19200/37800] Loss: 0.018548\n",
            "Epoch 5: [25600/37800] Loss: 0.008275\n",
            "Epoch 5: [32000/37800] Loss: 0.014341\n",
            "Test result on epoch 5: Avg loss is 0.000031, Accuracy: 99.309525% (New Best Score)\n",
            "Epoch 6: [0/37800] Loss: 0.006345\n",
            "Epoch 6: [6400/37800] Loss: 0.017068\n",
            "Epoch 6: [12800/37800] Loss: 0.027334\n",
            "Epoch 6: [19200/37800] Loss: 0.190522\n",
            "Epoch 6: [25600/37800] Loss: 0.006995\n",
            "Epoch 6: [32000/37800] Loss: 0.031379\n",
            "Test result on epoch 6: Avg loss is 0.000031, Accuracy: 99.357140% (New Best Score)\n",
            "Epoch 7: [0/37800] Loss: 0.020295\n",
            "Epoch 7: [6400/37800] Loss: 0.028096\n",
            "Epoch 7: [12800/37800] Loss: 0.015650\n",
            "Epoch 7: [19200/37800] Loss: 0.063235\n",
            "Epoch 7: [25600/37800] Loss: 0.002181\n",
            "Epoch 7: [32000/37800] Loss: 0.038220\n",
            "Test result on epoch 7: Avg loss is 0.000029, Accuracy: 99.333336% \n",
            "Epoch 8: [0/37800] Loss: 0.002216\n",
            "Epoch 8: [6400/37800] Loss: 0.013260\n",
            "Epoch 8: [12800/37800] Loss: 0.138866\n",
            "Epoch 8: [19200/37800] Loss: 0.003452\n",
            "Epoch 8: [25600/37800] Loss: 0.012999\n",
            "Epoch 8: [32000/37800] Loss: 0.005328\n",
            "Test result on epoch 8: Avg loss is 0.000023, Accuracy: 99.500000% (New Best Score)\n",
            "Epoch 9: [0/37800] Loss: 0.059099\n",
            "Epoch 9: [6400/37800] Loss: 0.003630\n",
            "Epoch 9: [12800/37800] Loss: 0.005263\n",
            "Epoch 9: [19200/37800] Loss: 0.002916\n",
            "Epoch 9: [25600/37800] Loss: 0.054841\n",
            "Epoch 9: [32000/37800] Loss: 0.014028\n",
            "Test result on epoch 9: Avg loss is 0.000035, Accuracy: 99.333336% \n",
            "Epoch 10: [0/37800] Loss: 0.009383\n",
            "Epoch 10: [6400/37800] Loss: 0.001552\n",
            "Epoch 10: [12800/37800] Loss: 0.052346\n",
            "Epoch 10: [19200/37800] Loss: 0.007463\n",
            "Epoch 10: [25600/37800] Loss: 0.002554\n",
            "Epoch 10: [32000/37800] Loss: 0.059848\n",
            "Test result on epoch 10: Avg loss is 0.000027, Accuracy: 99.476189% \n",
            "Epoch 11: [0/37800] Loss: 0.015404\n",
            "Epoch 11: [6400/37800] Loss: 0.050403\n",
            "Epoch 11: [12800/37800] Loss: 0.023253\n",
            "Epoch 11: [19200/37800] Loss: 0.017822\n",
            "Epoch 11: [25600/37800] Loss: 0.113957\n",
            "Epoch 11: [32000/37800] Loss: 0.004525\n",
            "Test result on epoch 11: Avg loss is 0.000056, Accuracy: 99.238091% \n",
            "Epoch 12: [0/37800] Loss: 0.079184\n",
            "Epoch 12: [6400/37800] Loss: 0.001507\n",
            "Epoch 12: [12800/37800] Loss: 0.015898\n",
            "Epoch 12: [19200/37800] Loss: 0.018968\n",
            "Epoch 12: [25600/37800] Loss: 0.041237\n",
            "Epoch 12: [32000/37800] Loss: 0.009806\n",
            "Test result on epoch 12: Avg loss is 0.000031, Accuracy: 99.261902% \n",
            "Epoch 13: [0/37800] Loss: 0.014411\n",
            "Epoch 13: [6400/37800] Loss: 0.005186\n",
            "Epoch 13: [12800/37800] Loss: 0.005040\n",
            "Epoch 13: [19200/37800] Loss: 0.034951\n",
            "Epoch 13: [25600/37800] Loss: 0.014704\n",
            "Epoch 13: [32000/37800] Loss: 0.002382\n",
            "Test result on epoch 13: Avg loss is 0.000035, Accuracy: 99.428574% \n",
            "Epoch 14: [0/37800] Loss: 0.009947\n",
            "Epoch 14: [6400/37800] Loss: 0.041448\n",
            "Epoch 14: [12800/37800] Loss: 0.002127\n",
            "Epoch 14: [19200/37800] Loss: 0.057776\n",
            "Epoch 14: [25600/37800] Loss: 0.005873\n",
            "Epoch 14: [32000/37800] Loss: 0.018973\n",
            "Test result on epoch 14: Avg loss is 0.000033, Accuracy: 99.452385% \n",
            "Epoch 15: [0/37800] Loss: 0.001816\n",
            "Epoch 15: [6400/37800] Loss: 0.006432\n",
            "Epoch 15: [12800/37800] Loss: 0.020375\n",
            "Epoch 15: [19200/37800] Loss: 0.009651\n",
            "Epoch 15: [25600/37800] Loss: 0.000717\n",
            "Epoch 15: [32000/37800] Loss: 0.060568\n",
            "Test result on epoch 15: Avg loss is 0.000038, Accuracy: 99.190475% \n",
            "Epoch 16: [0/37800] Loss: 0.122349\n",
            "Epoch 16: [6400/37800] Loss: 0.023329\n",
            "Epoch 16: [12800/37800] Loss: 0.046594\n",
            "Epoch 16: [19200/37800] Loss: 0.010738\n",
            "Epoch 16: [25600/37800] Loss: 0.002858\n",
            "Epoch 16: [32000/37800] Loss: 0.001555\n",
            "Test result on epoch 16: Avg loss is 0.000041, Accuracy: 99.357140% \n",
            "Epoch 17: [0/37800] Loss: 0.001624\n",
            "Epoch 17: [6400/37800] Loss: 0.089229\n",
            "Epoch 17: [12800/37800] Loss: 0.003032\n",
            "Epoch 17: [19200/37800] Loss: 0.064996\n",
            "Epoch 17: [25600/37800] Loss: 0.002517\n",
            "Epoch 17: [32000/37800] Loss: 0.016674\n",
            "Test result on epoch 17: Avg loss is 0.000044, Accuracy: 99.380951% \n",
            "Epoch 18: [0/37800] Loss: 0.007272\n",
            "Epoch 18: [6400/37800] Loss: 0.008354\n",
            "Epoch 18: [12800/37800] Loss: 0.000302\n",
            "Epoch 18: [19200/37800] Loss: 0.008531\n",
            "Epoch 18: [25600/37800] Loss: 0.015543\n",
            "Epoch 18: [32000/37800] Loss: 0.001374\n",
            "Test result on epoch 18: Avg loss is 0.000036, Accuracy: 99.380951% \n",
            "Epoch 19: [0/37800] Loss: 0.001511\n",
            "Epoch 19: [6400/37800] Loss: 0.000263\n",
            "Epoch 19: [12800/37800] Loss: 0.032428\n",
            "Epoch 19: [19200/37800] Loss: 0.009576\n",
            "Epoch 19: [25600/37800] Loss: 0.013781\n",
            "Epoch 19: [32000/37800] Loss: 0.018562\n",
            "Test result on epoch 19: Avg loss is 0.000036, Accuracy: 99.404755% \n",
            "Epoch 20: [0/37800] Loss: 0.002713\n",
            "Epoch 20: [6400/37800] Loss: 0.003997\n",
            "Epoch 20: [12800/37800] Loss: 0.000889\n",
            "Epoch 20: [19200/37800] Loss: 0.001460\n",
            "Epoch 20: [25600/37800] Loss: 0.001039\n",
            "Epoch 20: [32000/37800] Loss: 0.000240\n",
            "Test result on epoch 20: Avg loss is 0.000041, Accuracy: 99.428574% \n",
            "Epoch 21: [0/37800] Loss: 0.002813\n",
            "Epoch 21: [6400/37800] Loss: 0.010590\n",
            "Epoch 21: [12800/37800] Loss: 0.001470\n",
            "Epoch 21: [19200/37800] Loss: 0.001771\n",
            "Epoch 21: [25600/37800] Loss: 0.056297\n",
            "Epoch 21: [32000/37800] Loss: 0.020396\n",
            "Test result on epoch 21: Avg loss is 0.000033, Accuracy: 99.452385% \n",
            "Epoch 22: [0/37800] Loss: 0.040346\n",
            "Epoch 22: [6400/37800] Loss: 0.002197\n",
            "Epoch 22: [12800/37800] Loss: 0.001512\n",
            "Epoch 22: [19200/37800] Loss: 0.000070\n",
            "Epoch 22: [25600/37800] Loss: 0.000834\n",
            "Epoch 22: [32000/37800] Loss: 0.022632\n",
            "Test result on epoch 22: Avg loss is 0.000032, Accuracy: 99.357140% \n",
            "Epoch 23: [0/37800] Loss: 0.000689\n",
            "Epoch 23: [6400/37800] Loss: 0.002146\n",
            "Epoch 23: [12800/37800] Loss: 0.032013\n",
            "Epoch 23: [19200/37800] Loss: 0.003570\n",
            "Epoch 23: [25600/37800] Loss: 0.025278\n",
            "Epoch 23: [32000/37800] Loss: 0.000574\n",
            "Test result on epoch 23: Avg loss is 0.000029, Accuracy: 99.476189% \n",
            "Epoch 24: [0/37800] Loss: 0.008241\n",
            "Epoch 24: [6400/37800] Loss: 0.003480\n",
            "Epoch 24: [12800/37800] Loss: 0.001518\n",
            "Epoch 24: [19200/37800] Loss: 0.002582\n",
            "Epoch 24: [25600/37800] Loss: 0.002140\n",
            "Epoch 24: [32000/37800] Loss: 0.003227\n",
            "Test result on epoch 24: Avg loss is 0.000030, Accuracy: 99.476189% \n",
            "Epoch 25: [0/37800] Loss: 0.034100\n",
            "Epoch 25: [6400/37800] Loss: 0.000897\n",
            "Epoch 25: [12800/37800] Loss: 0.040112\n",
            "Epoch 25: [19200/37800] Loss: 0.070105\n",
            "Epoch 25: [25600/37800] Loss: 0.001172\n",
            "Epoch 25: [32000/37800] Loss: 0.000044\n",
            "Test result on epoch 25: Avg loss is 0.000032, Accuracy: 99.404755% \n",
            "Epoch 26: [0/37800] Loss: 0.000027\n",
            "Epoch 26: [6400/37800] Loss: 0.001647\n",
            "Epoch 26: [12800/37800] Loss: 0.003630\n",
            "Epoch 26: [19200/37800] Loss: 0.001357\n",
            "Epoch 26: [25600/37800] Loss: 0.000253\n",
            "Epoch 26: [32000/37800] Loss: 0.049454\n",
            "Test result on epoch 26: Avg loss is 0.000029, Accuracy: 99.404755% \n",
            "Epoch 27: [0/37800] Loss: 0.014757\n",
            "Epoch 27: [6400/37800] Loss: 0.013302\n",
            "Epoch 27: [12800/37800] Loss: 0.005144\n",
            "Epoch 27: [19200/37800] Loss: 0.004320\n",
            "Epoch 27: [25600/37800] Loss: 0.001653\n",
            "Epoch 27: [32000/37800] Loss: 0.000138\n",
            "Test result on epoch 27: Avg loss is 0.000029, Accuracy: 99.571426% (New Best Score)\n",
            "Epoch 28: [0/37800] Loss: 0.000965\n",
            "Epoch 28: [6400/37800] Loss: 0.000770\n",
            "Epoch 28: [12800/37800] Loss: 0.006967\n",
            "Epoch 28: [19200/37800] Loss: 0.000296\n",
            "Epoch 28: [25600/37800] Loss: 0.009317\n",
            "Epoch 28: [32000/37800] Loss: 0.001737\n",
            "Test result on epoch 28: Avg loss is 0.000031, Accuracy: 99.500000% \n",
            "Epoch 29: [0/37800] Loss: 0.001668\n",
            "Epoch 29: [6400/37800] Loss: 0.008455\n",
            "Epoch 29: [12800/37800] Loss: 0.000701\n",
            "Epoch 29: [19200/37800] Loss: 0.008399\n",
            "Epoch 29: [25600/37800] Loss: 0.004322\n",
            "Epoch 29: [32000/37800] Loss: 0.000408\n",
            "Test result on epoch 29: Avg loss is 0.000030, Accuracy: 99.500000% \n",
            "Epoch 30: [0/37800] Loss: 0.016296\n",
            "Epoch 30: [6400/37800] Loss: 0.008906\n",
            "Epoch 30: [12800/37800] Loss: 0.003381\n",
            "Epoch 30: [19200/37800] Loss: 0.062190\n",
            "Epoch 30: [25600/37800] Loss: 0.014093\n",
            "Epoch 30: [32000/37800] Loss: 0.000127\n",
            "Test result on epoch 30: Avg loss is 0.000032, Accuracy: 99.500000% \n"
          ]
        }
      ]
    }
  ]
}