{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognizer_lenet5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Recognizer with LeNet 5"
      ],
      "metadata": {
        "id": "HJtPRH2EoYGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "OZtKXy5Zprea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import libraries"
      ],
      "metadata": {
        "id": "rbKbDycDOrNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YeVrf_8uOp-d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Loading dataset from directory"
      ],
      "metadata": {
        "id": "W7PwRo8y1bT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive to Colab to serve as local directory\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo-PmqXwpvDN",
        "outputId": "7913c971-ac52-49c4-ef7b-63810b42b9ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "dir_root = \"/content/drive/MyDrive/Kaggle/Digit_Recognizer/Data/digit-recognizer\"\n",
        "train_dir = os.path.join(dir_root, \"train.csv\")\n",
        "train = pd.read_csv(train_dir, dtype=np.float32)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "_WDHLD-vqKwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "e16d041b-08d7-4d8f-e748-4ec81ff0ac36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "1    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "2    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "3    4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "4    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "1     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "2     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "3     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "4     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "   pixel780  pixel781  pixel782  pixel783  \n",
              "0       0.0       0.0       0.0       0.0  \n",
              "1       0.0       0.0       0.0       0.0  \n",
              "2       0.0       0.0       0.0       0.0  \n",
              "3       0.0       0.0       0.0       0.0  \n",
              "4       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c02fd6b3-3284-4f1f-85b5-21ee50642701\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c02fd6b3-3284-4f1f-85b5-21ee50642701')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c02fd6b3-3284-4f1f-85b5-21ee50642701 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c02fd6b3-3284-4f1f-85b5-21ee50642701');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and labels\n",
        "X_train = train.loc[:, train.columns != \"label\"]\n",
        "Y_train = train.label"
      ],
      "metadata": {
        "id": "tWd035ZyPXvZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Check for data inbalance or missing value"
      ],
      "metadata": {
        "id": "eNrNeKq5PrIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if contain null features\n",
        "X_train.isnull().any().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OouWHuxCP5Cy",
        "outputId": "53fd13e0-659f-49a5-b459-6bc9b5b86f8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       784\n",
              "unique        1\n",
              "top       False\n",
              "freq        784\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for counts\n",
        "label_count = Y_train.value_counts()\n",
        "print(label_count)\n",
        "g = sns.countplot(x=Y_train)\n",
        "g = g.set(xlabel=\"Label\", ylabel=\"Count\", title=\"Label Count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "LnSmSjN1SgFL",
        "outputId": "f3ceef53-ec3d-41d3-cb89-b86238f9fc8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    4684\n",
            "7.0    4401\n",
            "3.0    4351\n",
            "9.0    4188\n",
            "2.0    4177\n",
            "6.0    4137\n",
            "0.0    4132\n",
            "4.0    4072\n",
            "8.0    4063\n",
            "5.0    3795\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Normalization and transformation"
      ],
      "metadata": {
        "id": "nqnS993XLMCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Perform grayscale normalization to \n",
        "1. Reduce illumination differences\n",
        "2. Increase CNN covergence rate\n",
        "'''\n",
        "X_train = X_train / 255.0"
      ],
      "metadata": {
        "id": "T-6a45tkQvqY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training and test set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_train.values, \n",
        "    Y_train.values, \n",
        "    test_size=0.1, \n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# Reshape input image\n",
        "X_train = X_train.reshape((-1, 1, 28, 28))\n",
        "X_train = np.squeeze(X_train, axis=1)\n",
        "X_test = X_test.reshape((-1, 1, 28, 28))\n",
        "X_test = np.squeeze(X_test, axis=1)\n",
        "\n",
        "# Transform from numpy arrays to tensors\n",
        "Y_train = torch.from_numpy(Y_train).type(torch.FloatTensor)\n",
        "Y_test = torch.from_numpy(Y_test).type(torch.FloatTensor)"
      ],
      "metadata": {
        "id": "gw_Tj5EbRW_k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "g = plt.imshow(X_train[0][:,:], cmap=\"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XPRvYuhlXvr3",
        "outputId": "1efa5c83-bb10-4ccf-8a9d-f8f7e9896712"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MNIST data class\n",
        "transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "class MNIST(Dataset):\n",
        "    def __init__(self, X, Y, Transform):\n",
        "        self.X = X\n",
        "        self.transform = Transform\n",
        "        self.Y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transform(self.X[index]), self.Y[index]\n",
        "\n",
        "batch_size_train, batch_size_test = 64, 1000\n",
        "train_set = MNIST(X_train, Y_train, transform_train)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_set = MNIST(X_test, Y_test, transform_train)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size_test, shuffle=False)"
      ],
      "metadata": {
        "id": "P8drJS9eZi_S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "NS12pIuU0gIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create CNN Model"
      ],
      "metadata": {
        "id": "lH2lgR7V0kU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2EkUe-a61muz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03041f85-f1bf-48c6-c43d-8dedd8f3dd69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_feature = 10\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    '''\n",
        "    This implementation follow LeNet5's design from \"Gradient-based learning\n",
        "    applied to document recognition\" by Y.Lecun with several modifications.\n",
        "    \n",
        "    - Two 3x3 filters replaced single 5x5 filter in conv2d layer 3\n",
        "    - Batch normalization added\n",
        "    - ReLU activation function replaced tanh\n",
        "    - More channels added\n",
        "    - Dropout added\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(p=0.25),\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.Dropout2d(p=0.25),\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=3136, out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.BatchNorm1d(num_features=256),\n",
        "            nn.Linear(in_features=256, out_features=latent_feature)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Y-qTEHgRz4g9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Instantiate model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "FBZTpbZLftA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model and move to GPU if available\n",
        "model = LeNet5()\n",
        "LeNet5_classifier = model.to(device)\n",
        "\n",
        "# Instantiate loss function\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "# Instantiate optimizer\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(LeNet5_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Instantiate number of epoch, losses, score\n",
        "max_epoch = 30\n",
        "train_losses, test_losses = [], []\n",
        "acc_list = []\n",
        "best_score = 0\n",
        "best_model = None"
      ],
      "metadata": {
        "id": "PTqoB-1RfEEj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train and test the model"
      ],
      "metadata": {
        "id": "7AKTJ0Xnf87X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(classifier, epoch):\n",
        "\n",
        "    classifier.train()\n",
        "\n",
        "    for idx, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = classifier(images)\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 10 == 0: # Record output every 10 batches\n",
        "            train_losses.append(loss.item())\n",
        "        if idx % 100 == 0: # Visualize output every 100 batches\n",
        "            print(f\"Epoch {epoch}: [{idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item():.6f}\")"
      ],
      "metadata": {
        "id": "tz9KwFb6ljRI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(classifier, epoch, best_score):\n",
        "    \n",
        "    classifier.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in enumerate(test_loader):\n",
        "            \n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = classifier(images)\n",
        "            test_loss += loss_fn(output, labels).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1] # Get estimate of result by looking at largest class value\n",
        "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
        "    \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    acc_val = correct/len(test_loader.dataset)\n",
        "    acc_val = acc_val.cpu()\n",
        "    acc_list.append(acc_val)\n",
        "    print(f\"Test result on epoch {epoch}: Avg loss is {test_loss:.6f}, Accuracy: {100.*acc_val:.6f}%\", end=\" \")\n",
        "    if best_score <= acc_val:\n",
        "        best_score = acc_val\n",
        "        best_model = copy.deepcopy(classifier)\n",
        "        print(\"(New Best Score)\")\n",
        "    else:\n",
        "        print()\n",
        "    return best_score"
      ],
      "metadata": {
        "id": "hnEbQWnFgjGj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, max_epoch+1):\n",
        "    train(LeNet5_classifier, epoch)\n",
        "    best_score = test(LeNet5_classifier, epoch, best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQsPY4bNfO48",
        "outputId": "037e7059-5160-4707-a643-30704adf39da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: [0/37800] Loss: 2.380991\n",
            "Epoch 1: [6400/37800] Loss: 0.229065\n",
            "Epoch 1: [12800/37800] Loss: 0.121981\n",
            "Epoch 1: [19200/37800] Loss: 0.086244\n",
            "Epoch 1: [25600/37800] Loss: 0.086490\n",
            "Epoch 1: [32000/37800] Loss: 0.296446\n",
            "Test result on epoch 1: Avg loss is 0.000052, Accuracy: 98.547623% (New Best Score)\n",
            "Epoch 2: [0/37800] Loss: 0.055228\n",
            "Epoch 2: [6400/37800] Loss: 0.192222\n",
            "Epoch 2: [12800/37800] Loss: 0.089150\n",
            "Epoch 2: [19200/37800] Loss: 0.110543\n",
            "Epoch 2: [25600/37800] Loss: 0.024209\n",
            "Epoch 2: [32000/37800] Loss: 0.019258\n",
            "Test result on epoch 2: Avg loss is 0.000045, Accuracy: 98.809525% (New Best Score)\n",
            "Epoch 3: [0/37800] Loss: 0.050790\n",
            "Epoch 3: [6400/37800] Loss: 0.010111\n",
            "Epoch 3: [12800/37800] Loss: 0.059535\n",
            "Epoch 3: [19200/37800] Loss: 0.034237\n",
            "Epoch 3: [25600/37800] Loss: 0.100039\n",
            "Epoch 3: [32000/37800] Loss: 0.005887\n",
            "Test result on epoch 3: Avg loss is 0.000038, Accuracy: 99.095238% (New Best Score)\n",
            "Epoch 4: [0/37800] Loss: 0.025540\n",
            "Epoch 4: [6400/37800] Loss: 0.018468\n",
            "Epoch 4: [12800/37800] Loss: 0.021764\n",
            "Epoch 4: [19200/37800] Loss: 0.039961\n",
            "Epoch 4: [25600/37800] Loss: 0.190901\n",
            "Epoch 4: [32000/37800] Loss: 0.012776\n",
            "Test result on epoch 4: Avg loss is 0.000032, Accuracy: 99.095238% (New Best Score)\n",
            "Epoch 5: [0/37800] Loss: 0.022647\n",
            "Epoch 5: [6400/37800] Loss: 0.004643\n",
            "Epoch 5: [12800/37800] Loss: 0.003926\n",
            "Epoch 5: [19200/37800] Loss: 0.006624\n",
            "Epoch 5: [25600/37800] Loss: 0.031570\n",
            "Epoch 5: [32000/37800] Loss: 0.072079\n",
            "Test result on epoch 5: Avg loss is 0.000051, Accuracy: 99.095238% (New Best Score)\n",
            "Epoch 6: [0/37800] Loss: 0.027441\n",
            "Epoch 6: [6400/37800] Loss: 0.041431\n",
            "Epoch 6: [12800/37800] Loss: 0.003225\n",
            "Epoch 6: [19200/37800] Loss: 0.019470\n",
            "Epoch 6: [25600/37800] Loss: 0.223317\n",
            "Epoch 6: [32000/37800] Loss: 0.046983\n",
            "Test result on epoch 6: Avg loss is 0.000034, Accuracy: 99.190475% (New Best Score)\n",
            "Epoch 7: [0/37800] Loss: 0.005429\n",
            "Epoch 7: [6400/37800] Loss: 0.005373\n",
            "Epoch 7: [12800/37800] Loss: 0.062388\n",
            "Epoch 7: [19200/37800] Loss: 0.026359\n",
            "Epoch 7: [25600/37800] Loss: 0.029299\n",
            "Epoch 7: [32000/37800] Loss: 0.011103\n",
            "Test result on epoch 7: Avg loss is 0.000031, Accuracy: 99.357140% (New Best Score)\n",
            "Epoch 8: [0/37800] Loss: 0.011539\n",
            "Epoch 8: [6400/37800] Loss: 0.002819\n",
            "Epoch 8: [12800/37800] Loss: 0.017819\n",
            "Epoch 8: [19200/37800] Loss: 0.007427\n",
            "Epoch 8: [25600/37800] Loss: 0.008603\n",
            "Epoch 8: [32000/37800] Loss: 0.026034\n",
            "Test result on epoch 8: Avg loss is 0.000030, Accuracy: 99.285713% \n",
            "Epoch 9: [0/37800] Loss: 0.007899\n",
            "Epoch 9: [6400/37800] Loss: 0.010131\n",
            "Epoch 9: [12800/37800] Loss: 0.044707\n",
            "Epoch 9: [19200/37800] Loss: 0.052460\n",
            "Epoch 9: [25600/37800] Loss: 0.009296\n",
            "Epoch 9: [32000/37800] Loss: 0.015747\n",
            "Test result on epoch 9: Avg loss is 0.000040, Accuracy: 99.095238% \n",
            "Epoch 10: [0/37800] Loss: 0.003613\n",
            "Epoch 10: [6400/37800] Loss: 0.019986\n",
            "Epoch 10: [12800/37800] Loss: 0.002943\n",
            "Epoch 10: [19200/37800] Loss: 0.004634\n",
            "Epoch 10: [25600/37800] Loss: 0.061929\n",
            "Epoch 10: [32000/37800] Loss: 0.013902\n",
            "Test result on epoch 10: Avg loss is 0.000026, Accuracy: 99.333336% \n",
            "Epoch 11: [0/37800] Loss: 0.013440\n",
            "Epoch 11: [6400/37800] Loss: 0.004148\n",
            "Epoch 11: [12800/37800] Loss: 0.005040\n",
            "Epoch 11: [19200/37800] Loss: 0.036332\n",
            "Epoch 11: [25600/37800] Loss: 0.012292\n",
            "Epoch 11: [32000/37800] Loss: 0.001785\n",
            "Test result on epoch 11: Avg loss is 0.000025, Accuracy: 99.333336% \n",
            "Epoch 12: [0/37800] Loss: 0.007721\n",
            "Epoch 12: [6400/37800] Loss: 0.007289\n",
            "Epoch 12: [12800/37800] Loss: 0.005227\n",
            "Epoch 12: [19200/37800] Loss: 0.043904\n",
            "Epoch 12: [25600/37800] Loss: 0.000506\n",
            "Epoch 12: [32000/37800] Loss: 0.070879\n",
            "Test result on epoch 12: Avg loss is 0.000033, Accuracy: 99.285713% \n",
            "Epoch 13: [0/37800] Loss: 0.004609\n",
            "Epoch 13: [6400/37800] Loss: 0.005350\n",
            "Epoch 13: [12800/37800] Loss: 0.011592\n",
            "Epoch 13: [19200/37800] Loss: 0.011194\n",
            "Epoch 13: [25600/37800] Loss: 0.005673\n",
            "Epoch 13: [32000/37800] Loss: 0.055256\n",
            "Test result on epoch 13: Avg loss is 0.000029, Accuracy: 99.333336% \n",
            "Epoch 14: [0/37800] Loss: 0.006144\n",
            "Epoch 14: [6400/37800] Loss: 0.014106\n",
            "Epoch 14: [12800/37800] Loss: 0.022655\n",
            "Epoch 14: [19200/37800] Loss: 0.005143\n",
            "Epoch 14: [25600/37800] Loss: 0.002543\n",
            "Epoch 14: [32000/37800] Loss: 0.009082\n",
            "Test result on epoch 14: Avg loss is 0.000039, Accuracy: 99.214287% \n",
            "Epoch 15: [0/37800] Loss: 0.025647\n",
            "Epoch 15: [6400/37800] Loss: 0.017079\n",
            "Epoch 15: [12800/37800] Loss: 0.009623\n",
            "Epoch 15: [19200/37800] Loss: 0.017909\n",
            "Epoch 15: [25600/37800] Loss: 0.006857\n",
            "Epoch 15: [32000/37800] Loss: 0.003878\n",
            "Test result on epoch 15: Avg loss is 0.000036, Accuracy: 99.285713% \n",
            "Epoch 16: [0/37800] Loss: 0.038771\n",
            "Epoch 16: [6400/37800] Loss: 0.012620\n",
            "Epoch 16: [12800/37800] Loss: 0.017257\n",
            "Epoch 16: [19200/37800] Loss: 0.024631\n",
            "Epoch 16: [25600/37800] Loss: 0.000966\n",
            "Epoch 16: [32000/37800] Loss: 0.013442\n",
            "Test result on epoch 16: Avg loss is 0.000028, Accuracy: 99.380951% (New Best Score)\n",
            "Epoch 17: [0/37800] Loss: 0.000708\n",
            "Epoch 17: [6400/37800] Loss: 0.001036\n",
            "Epoch 17: [12800/37800] Loss: 0.001860\n",
            "Epoch 17: [19200/37800] Loss: 0.000888\n",
            "Epoch 17: [25600/37800] Loss: 0.023644\n",
            "Epoch 17: [32000/37800] Loss: 0.016111\n",
            "Test result on epoch 17: Avg loss is 0.000034, Accuracy: 99.333336% \n",
            "Epoch 18: [0/37800] Loss: 0.000348\n",
            "Epoch 18: [6400/37800] Loss: 0.005026\n",
            "Epoch 18: [12800/37800] Loss: 0.005035\n",
            "Epoch 18: [19200/37800] Loss: 0.013516\n",
            "Epoch 18: [25600/37800] Loss: 0.001062\n",
            "Epoch 18: [32000/37800] Loss: 0.001414\n",
            "Test result on epoch 18: Avg loss is 0.000024, Accuracy: 99.404755% (New Best Score)\n",
            "Epoch 19: [0/37800] Loss: 0.004971\n",
            "Epoch 19: [6400/37800] Loss: 0.000966\n",
            "Epoch 19: [12800/37800] Loss: 0.002618\n",
            "Epoch 19: [19200/37800] Loss: 0.020743\n",
            "Epoch 19: [25600/37800] Loss: 0.027987\n",
            "Epoch 19: [32000/37800] Loss: 0.003806\n",
            "Test result on epoch 19: Avg loss is 0.000030, Accuracy: 99.476189% (New Best Score)\n",
            "Epoch 20: [0/37800] Loss: 0.000766\n",
            "Epoch 20: [6400/37800] Loss: 0.019499\n",
            "Epoch 20: [12800/37800] Loss: 0.019709\n",
            "Epoch 20: [19200/37800] Loss: 0.001124\n",
            "Epoch 20: [25600/37800] Loss: 0.028727\n",
            "Epoch 20: [32000/37800] Loss: 0.002549\n",
            "Test result on epoch 20: Avg loss is 0.000035, Accuracy: 99.166664% \n",
            "Epoch 21: [0/37800] Loss: 0.000269\n",
            "Epoch 21: [6400/37800] Loss: 0.014139\n",
            "Epoch 21: [12800/37800] Loss: 0.001797\n",
            "Epoch 21: [19200/37800] Loss: 0.003099\n",
            "Epoch 21: [25600/37800] Loss: 0.052079\n",
            "Epoch 21: [32000/37800] Loss: 0.013136\n",
            "Test result on epoch 21: Avg loss is 0.000034, Accuracy: 99.380951% \n",
            "Epoch 22: [0/37800] Loss: 0.004038\n",
            "Epoch 22: [6400/37800] Loss: 0.018182\n",
            "Epoch 22: [12800/37800] Loss: 0.032148\n",
            "Epoch 22: [19200/37800] Loss: 0.011707\n",
            "Epoch 22: [25600/37800] Loss: 0.002425\n",
            "Epoch 22: [32000/37800] Loss: 0.072101\n",
            "Test result on epoch 22: Avg loss is 0.000029, Accuracy: 99.357140% \n",
            "Epoch 23: [0/37800] Loss: 0.000709\n",
            "Epoch 23: [6400/37800] Loss: 0.012350\n",
            "Epoch 23: [12800/37800] Loss: 0.000190\n",
            "Epoch 23: [19200/37800] Loss: 0.021076\n",
            "Epoch 23: [25600/37800] Loss: 0.006013\n",
            "Epoch 23: [32000/37800] Loss: 0.031286\n",
            "Test result on epoch 23: Avg loss is 0.000035, Accuracy: 99.333336% \n",
            "Epoch 24: [0/37800] Loss: 0.002487\n",
            "Epoch 24: [6400/37800] Loss: 0.000460\n",
            "Epoch 24: [12800/37800] Loss: 0.002495\n",
            "Epoch 24: [19200/37800] Loss: 0.000498\n",
            "Epoch 24: [25600/37800] Loss: 0.035639\n",
            "Epoch 24: [32000/37800] Loss: 0.001712\n",
            "Test result on epoch 24: Avg loss is 0.000039, Accuracy: 99.309525% \n",
            "Epoch 25: [0/37800] Loss: 0.000694\n",
            "Epoch 25: [6400/37800] Loss: 0.034244\n",
            "Epoch 25: [12800/37800] Loss: 0.002069\n",
            "Epoch 25: [19200/37800] Loss: 0.002419\n",
            "Epoch 25: [25600/37800] Loss: 0.001296\n",
            "Epoch 25: [32000/37800] Loss: 0.001127\n",
            "Test result on epoch 25: Avg loss is 0.000029, Accuracy: 99.428574% \n",
            "Epoch 26: [0/37800] Loss: 0.001232\n",
            "Epoch 26: [6400/37800] Loss: 0.010347\n",
            "Epoch 26: [12800/37800] Loss: 0.004141\n",
            "Epoch 26: [19200/37800] Loss: 0.003102\n",
            "Epoch 26: [25600/37800] Loss: 0.042559\n",
            "Epoch 26: [32000/37800] Loss: 0.009848\n",
            "Test result on epoch 26: Avg loss is 0.000036, Accuracy: 99.380951% \n",
            "Epoch 27: [0/37800] Loss: 0.000427\n",
            "Epoch 27: [6400/37800] Loss: 0.065982\n",
            "Epoch 27: [12800/37800] Loss: 0.000299\n",
            "Epoch 27: [19200/37800] Loss: 0.038287\n",
            "Epoch 27: [25600/37800] Loss: 0.000585\n",
            "Epoch 27: [32000/37800] Loss: 0.115862\n",
            "Test result on epoch 27: Avg loss is 0.000035, Accuracy: 99.309525% \n",
            "Epoch 28: [0/37800] Loss: 0.010756\n",
            "Epoch 28: [6400/37800] Loss: 0.000230\n",
            "Epoch 28: [12800/37800] Loss: 0.000132\n",
            "Epoch 28: [19200/37800] Loss: 0.000026\n",
            "Epoch 28: [25600/37800] Loss: 0.004938\n",
            "Epoch 28: [32000/37800] Loss: 0.001109\n",
            "Test result on epoch 28: Avg loss is 0.000035, Accuracy: 99.190475% \n",
            "Epoch 29: [0/37800] Loss: 0.012138\n",
            "Epoch 29: [6400/37800] Loss: 0.000626\n",
            "Epoch 29: [12800/37800] Loss: 0.009912\n",
            "Epoch 29: [19200/37800] Loss: 0.000587\n",
            "Epoch 29: [25600/37800] Loss: 0.000873\n",
            "Epoch 29: [32000/37800] Loss: 0.067091\n",
            "Test result on epoch 29: Avg loss is 0.000033, Accuracy: 99.404755% \n",
            "Epoch 30: [0/37800] Loss: 0.003838\n",
            "Epoch 30: [6400/37800] Loss: 0.035891\n",
            "Epoch 30: [12800/37800] Loss: 0.001187\n",
            "Epoch 30: [19200/37800] Loss: 0.058496\n",
            "Epoch 30: [25600/37800] Loss: 0.000182\n",
            "Epoch 30: [32000/37800] Loss: 0.000464\n",
            "Test result on epoch 30: Avg loss is 0.000038, Accuracy: 99.333336% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization Result"
      ],
      "metadata": {
        "id": "jryCGn3a-s10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create graph object\n",
        "fig = go.Figure()\n",
        "\n",
        "label_name = [\"Loss\", \"Accuracy\"]\n",
        "colors = [\"rgb(67, 67, 67)\", \"rgb(49, 130, 189)\"]\n",
        "line_size = [2, 2]\n",
        "mode_size = [8, 8]\n",
        "\n",
        "# X is number of epoch, y is loss and accuracy\n",
        "x_data = np.vstack((np.arange(1, max_epoch+1),)*2)\n",
        "y_data = np.array([test_losses, acc_list])\n",
        "\n",
        "# Adding line\n",
        "for i in range(0, 2):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=x_data[i],\n",
        "        y=y_data[i],\n",
        "        mode=\"lines\",\n",
        "        name=label_name[i],\n",
        "        line=dict(color=colors[i], width=line_size[i]),\n",
        "        connectgaps=True\n",
        "    ))\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[x_data[i][0], x_data[i][-1]],\n",
        "        y=[y_data[i][0], y_data[i][-1]],\n",
        "        mode=\"markers\",\n",
        "        marker=dict(color=colors[i], size=mode_size[i])\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis=dict(\n",
        "        showline=True,\n",
        "        showgrid=False,\n",
        "        showticklabels=True,\n",
        "        linecolor='rgb(204, 204, 204)',\n",
        "        linewidth=2,\n",
        "        ticks='outside',\n",
        "        tickfont=dict(\n",
        "            family='Arial',\n",
        "            size=12,\n",
        "            color='rgb(82, 82, 82)',\n",
        "        ),\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        showgrid=False,\n",
        "        zeroline=False,\n",
        "        showline=False,\n",
        "        showticklabels=False,\n",
        "    ),\n",
        "    autosize=False,\n",
        "    margin=dict(\n",
        "        autoexpand=False,\n",
        "        l=100,\n",
        "        r=150,\n",
        "        t=100,\n",
        "    ),\n",
        "    showlegend=True,\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "\n",
        "annotations = []\n",
        "\n",
        "# Adding labels\n",
        "for y_trace, label, color in zip(y_data, label_name, colors):\n",
        "    # Label left side\n",
        "    annotations.append(dict(\n",
        "        xref='paper', \n",
        "        x=0.05, \n",
        "        y=y_trace[0],\n",
        "        xanchor='right', \n",
        "        yanchor='middle',\n",
        "        text=label + ' {:.2f}'.format(y_trace[0]),\n",
        "        font=dict(family='Arial', size=16),\n",
        "        showarrow=False\n",
        "        ))\n",
        "    # Label right side\n",
        "    annotations.append(dict(\n",
        "        xref='paper', \n",
        "        x=0.95, \n",
        "        y=y_trace[max_epoch-1],\n",
        "        xanchor='left', \n",
        "        yanchor='middle',\n",
        "        text='{:.4f}%'.format(y_trace[max_epoch-1]),\n",
        "        font=dict(family='Arial', size=16),\n",
        "        showarrow=False\n",
        "        ))\n",
        "\n",
        "# Adding title\n",
        "annotations.append(dict(\n",
        "    xref='paper', \n",
        "    yref='paper', \n",
        "    x=0.0, \n",
        "    y=1.05,\n",
        "    xanchor='left', \n",
        "    yanchor='bottom',\n",
        "    text='Training Loss and Accuracy',\n",
        "    font=dict(family='Arial',\n",
        "    size=30,\n",
        "    color='rgb(37,37,37)'),\n",
        "    showarrow=False\n",
        "    ))\n",
        "\n",
        "# Source\n",
        "annotations.append(dict(\n",
        "    xref='paper', \n",
        "    yref='paper', \n",
        "    x=0.5, y=-0.1,\n",
        "    xanchor='center', \n",
        "    yanchor='top',\n",
        "    text='Epochs',\n",
        "    font=dict(family='Arial', size=12, color='rgb(150,150,150)'),\n",
        "    showarrow=False\n",
        "    ))\n",
        "\n",
        "fig.update_layout(annotations=annotations,height=600, width=1000)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "-oquM94n-w0j",
        "outputId": "2d302539-de25-4a7b-9905-65c37dd5f8fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b2904321-0e34-445b-aca7-d1acd0918180\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2904321-0e34-445b-aca7-d1acd0918180\")) {                    Plotly.newPlot(                        \"b2904321-0e34-445b-aca7-d1acd0918180\",                        [{\"connectgaps\":true,\"line\":{\"color\":\"rgb(67, 67, 67)\",\"width\":2},\"mode\":\"lines\",\"name\":\"Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\"y\":[5.221881681964511e-05,4.462937380941141e-05,3.84535121598414e-05,3.161449473173845e-05,5.139340868308431e-05,3.399476542004517e-05,3.112641251867726e-05,3.0138040227549416e-05,4.023048538892042e-05,2.6444451927783942e-05,2.4657959473275002e-05,3.300467727794534e-05,2.938878323350634e-05,3.9483739861420225e-05,3.5513932151453834e-05,2.7515778451093605e-05,3.4426010790325344e-05,2.382645206082435e-05,2.9860777292577995e-05,3.545505526874746e-05,3.39886648136945e-05,2.899640217600834e-05,3.513012924009845e-05,3.8713555383895124e-05,2.9314016878959677e-05,3.5832859354004974e-05,3.508940516483216e-05,3.50748873980982e-05,3.346561509672375e-05,3.834292469989686e-05],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(67, 67, 67)\",\"size\":8},\"mode\":\"markers\",\"x\":[1,30],\"y\":[5.221881681964511e-05,3.834292469989686e-05],\"type\":\"scatter\"},{\"connectgaps\":true,\"line\":{\"color\":\"rgb(49, 130, 189)\",\"width\":2},\"mode\":\"lines\",\"name\":\"Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\"y\":[0.9854761958122253,0.988095223903656,0.9909523725509644,0.9909523725509644,0.9909523725509644,0.9919047355651855,0.993571400642395,0.9928571581840515,0.9909523725509644,0.9933333396911621,0.9933333396911621,0.9928571581840515,0.9933333396911621,0.9921428561210632,0.9928571581840515,0.9938095211982727,0.9933333396911621,0.9940475821495056,0.9947618842124939,0.9916666746139526,0.9938095211982727,0.993571400642395,0.9933333396911621,0.9930952191352844,0.9942857027053833,0.9938095211982727,0.9930952191352844,0.9919047355651855,0.9940475821495056,0.9933333396911621],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(49, 130, 189)\",\"size\":8},\"mode\":\"markers\",\"x\":[1,30],\"y\":[0.9854761958122253,0.9933333396911621],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"tickfont\":{\"family\":\"Arial\",\"size\":12,\"color\":\"rgb(82, 82, 82)\"},\"showline\":true,\"showgrid\":false,\"showticklabels\":true,\"linecolor\":\"rgb(204, 204, 204)\",\"linewidth\":2,\"ticks\":\"outside\"},\"yaxis\":{\"showgrid\":false,\"zeroline\":false,\"showline\":false,\"showticklabels\":false},\"margin\":{\"autoexpand\":false,\"l\":100,\"r\":150,\"t\":100},\"autosize\":false,\"showlegend\":true,\"plot_bgcolor\":\"white\",\"annotations\":[{\"font\":{\"family\":\"Arial\",\"size\":16},\"showarrow\":false,\"text\":\"Loss 0.00\",\"x\":0.05,\"xanchor\":\"right\",\"xref\":\"paper\",\"y\":5.221881681964511e-05,\"yanchor\":\"middle\"},{\"font\":{\"family\":\"Arial\",\"size\":16},\"showarrow\":false,\"text\":\"0.0000%\",\"x\":0.95,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":3.834292469989686e-05,\"yanchor\":\"middle\"},{\"font\":{\"family\":\"Arial\",\"size\":16},\"showarrow\":false,\"text\":\"Accuracy 0.99\",\"x\":0.05,\"xanchor\":\"right\",\"xref\":\"paper\",\"y\":0.9854761958122253,\"yanchor\":\"middle\"},{\"font\":{\"family\":\"Arial\",\"size\":16},\"showarrow\":false,\"text\":\"0.9933%\",\"x\":0.95,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.9933333396911621,\"yanchor\":\"middle\"},{\"font\":{\"color\":\"rgb(37,37,37)\",\"family\":\"Arial\",\"size\":30},\"showarrow\":false,\"text\":\"Training Loss and Accuracy\",\"x\":0.0,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":1.05,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"color\":\"rgb(150,150,150)\",\"family\":\"Arial\",\"size\":12},\"showarrow\":false,\"text\":\"Epochs\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":-0.1,\"yanchor\":\"top\",\"yref\":\"paper\"}],\"height\":600,\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b2904321-0e34-445b-aca7-d1acd0918180');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}